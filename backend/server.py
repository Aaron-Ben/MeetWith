"""
ä½œä¸º AI æœåŠ¡çš„ä¸­é—´å±‚
"""

import os
import re
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
from contextlib import asynccontextmanager

from fastapi import FastAPI, Request, Response
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import httpx
from pytz import timezone
from dotenv import load_dotenv

from plugin_manager import plugin_manager
from code_executor import execute_ai_code, CodeExecutionError

config_path = Path(__file__).parent / 'config.env'
load_dotenv(config_path)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# é…ç½®å¸¸é‡
DEBUG_MODE = os.getenv('DebugMode', 'false').lower() == 'true'
SHOW_VCP_OUTPUT = os.getenv('ShowVCP', 'false').lower() == 'true'
PORT = int(os.getenv('PORT', 6005))
API_KEY = os.getenv('API_Key')
API_URL = os.getenv('API_URL')
SERVER_KEY = os.getenv('Key')

DEBUG_LOG_DIR = Path(__file__).parent / 'DebugLog'

# è¡¨æƒ…åŒ…ç¼“å­˜
cached_emoji_lists: Dict[str, str] = {}

# åŠ è½½ç³»ç»Ÿæç¤ºè¯è½¬æ¢è§„åˆ™
detectors = []
for key in os.environ:
    if re.match(r'^Detector\d+$', key):
        index = key[8:]  # ç§»é™¤ 'Detector' å‰ç¼€
        output_key = f'Detector_Output{index}'
        if os.getenv(output_key):
            detectors.append({
                'detector': os.getenv(key),
                'output': os.getenv(output_key)
            })

if detectors:
    logger.info(f"å…±åŠ è½½äº† {len(detectors)} æ¡ç³»ç»Ÿæç¤ºè¯è½¬æ¢è§„åˆ™")
else:
    logger.info('æœªåŠ è½½ä»»ä½•ç³»ç»Ÿæç¤ºè¯è½¬æ¢è§„åˆ™')

# åŠ è½½å…¨å±€ä¸Šä¸‹æ–‡è½¬æ¢è§„åˆ™
super_detectors = []
for key in os.environ:
    if re.match(r'^SuperDetector\d+$', key):
        index = key[13:]  # ç§»é™¤ 'SuperDetector' å‰ç¼€
        output_key = f'SuperDetector_Output{index}'
        if os.getenv(output_key):
            super_detectors.append({
                'detector': os.getenv(key),
                'output': os.getenv(output_key)
            })

if super_detectors:
    logger.info(f"å…±åŠ è½½äº† {len(super_detectors)} æ¡å…¨å±€ä¸Šä¸‹æ–‡è½¬æ¢è§„åˆ™")
else:
    logger.info('æœªåŠ è½½ä»»ä½•å…¨å±€ä¸Šä¸‹æ–‡è½¬æ¢è§„åˆ™')


# ==================== å·¥å…·å‡½æ•° ====================

async def ensure_debug_log_dir():
    """ç¡®ä¿è°ƒè¯•æ—¥å¿—ç›®å½•å­˜åœ¨"""
    if DEBUG_MODE:
        DEBUG_LOG_DIR.mkdir(parents=True, exist_ok=True)


async def write_debug_log(filename_prefix: str, data: Any):
    """å†™å…¥è°ƒè¯•æ—¥å¿—"""
    if DEBUG_MODE:
        await ensure_debug_log_dir()
        now = datetime.now()
        timestamp = now.strftime('%Y%m%d_%H%M%S_%f')
        filename = f"{filename_prefix}-{timestamp}.txt"
        filepath = DEBUG_LOG_DIR / filename

        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(json.dumps(data, indent=2, ensure_ascii=False))
            logger.info(f"[DebugLog] å·²è®°å½•æ—¥å¿—: {filename}")
        except Exception as e:
            logger.error(f"å†™å…¥è°ƒè¯•æ—¥å¿—å¤±è´¥: {filepath}, é”™è¯¯: {e}")


def get_current_time(format_str: str = '%Yå¹´%mæœˆ%dæ—¥', tz: str = 'Asia/Shanghai') -> str:
    """è·å–å½“å‰æ—¶é—´"""
    now = datetime.now(timezone(tz))
    return now.strftime(format_str)


# ==================== MCP Tools API Prompt ====================

USE_MCP_CODE_EXECUTION = os.getenv('USE_MCP_CODE_EXECUTION', 'false').lower() == 'true'


async def _generate_tools_api_prompt() -> str:
    """
    Generate the tools API prompt for system instructions.

    This provides a hybrid approach: AI can choose between
    1. Writing Python code to process data and call tools
    2. Direct tool calls using VCP format (for simple tasks)
    """
    # Check if MCP mode is enabled
    if not USE_MCP_CODE_EXECUTION:
        return ""

    # Count available tools
    tools_dir = Path(__file__).parent / 'tools'
    tool_count = 0
    tool_categories = []

    if tools_dir.exists():
        for plugin_dir in tools_dir.iterdir():
            if plugin_dir.is_dir() and not plugin_dir.name.startswith('_'):
                func_files = list(plugin_dir.glob('*.py'))
                func_files = [f for f in func_files if not f.name.startswith('_')]
                if func_files:
                    tool_count += len(func_files)
                    tool_categories.append((plugin_dir.name, len(func_files)))

    # Generate hybrid prompt
    prompt = f"""
## Available Tools ({tool_count} total)

You have **TWO ways** to use tools:

### Option 1: Write Python Code (Recommended for complex tasks) ğŸ’¡

Write Python code to process data and call tools. This is **more efficient** because:
- Process intermediate results in code (not in model context)
- Use loops, conditionals, filtering
- Save tokens by only outputting what user needs

```python
from tools.tavilysearch import tavily_search
from tools.scicalculator import scicalculator

# Example: Process weather data
weather = await tavily_search(query="æ­¦æ±‰å¤©æ°”")
result = await scicalculator(expression="5 * 10")
print(f"ç»“æœ: {{result}}")
```

**When to use code execution:**
- Processing large datasets (filter, aggregate)
- Multiple tool calls with data flow between them
- Complex logic (loops, conditionals)
- When you want to minimize token usage

### Option 2: Direct Tool Call (Simple tasks)

Use VCP format for simple, single tool calls:

```
<<<[TOOL_REQUEST]>>>
tool_name:ã€Œå§‹ã€ToolNameã€Œæœ«ã€,
param:ã€Œå§‹ã€valueã€Œæœ«ã€
<<<[END_TOOL_REQUEST]>>>
```

**When to use direct calls:**
- Single, simple tool call
- Quick lookup
- When code execution feels like overkill

### Tool Discovery

```python
# List all available tools
from tools.search_tools import list_available_tools
tools = list_available_tools()

# Search for relevant tools
from tools.search_tools import search_tools
results = search_tools("search web", limit=5)

# Get info about a specific tool
from tools.tavilysearch import tavily_search
help(tavily_search)
```

### Tool Categories

"""

    # Add categories based on plugin directories
    for plugin_name, count in sorted(tool_categories):
        prompt += f"- **{plugin_name}**: {count} function(s)\n"

    prompt += """
### Important Notes

1. All tool functions are async - use `await` when calling them
2. Code execution results are automatically included in your next response
3. Choose code execution when it helps reduce token usage or handle complex logic
4. For simple tasks, direct VCP tool calls work fine

### How It Works

When you write Python code:
```python
# Your code is executed
result = await some_tool(param="value")
print(f"Got: {{result}}")
# The output is captured and sent back to you
```

When you use VCP format:
```
<<<[TOOL_REQUEST]>>>
tool_name:ã€Œå§‹ã€ToolNameã€Œæœ«ã€
<<<[END_TOOL_REQUEST]>>>
# The system detects this, executes the tool, and returns results
```

Both approaches work - choose based on the task complexity!
"""

    return prompt


def _get_mcp_tool_reference(plugin_name: str) -> str:
    """
    Generate minimal tool reference for MCP mode.

    Instead of full description, just mention the tool exists and how to import it.
    """
    plugin_name_lower = plugin_name.lower()
    return f"# Tool available: {plugin_name}\n# Import: from tools.{plugin_name_lower} import *"


# ==================== å˜é‡æ›¿æ¢ç³»ç»Ÿ ====================

async def replace_common_variables(text: Any) -> Any:
    """
    æ›¿æ¢é€šç”¨å˜é‡å ä½ç¬¦
    æ”¯æŒ: {{Date}}, {{Time}}, {{Today}}, {{Festival}}, {{VCPWeatherInfo}} ç­‰
    """
    if text is None:
        return ''

    processed_text = str(text)
    now = datetime.now(timezone('Asia/Shanghai'))

    # æ—¶é—´å˜é‡
    date_str = now.strftime('%Yå¹´%mæœˆ%dæ—¥')
    processed_text = processed_text.replace('{{Date}}', date_str)

    time_str = now.strftime('%H:%M:%S')
    processed_text = processed_text.replace('{{Time}}', time_str)

    today_str = now.strftime('%A')
    processed_text = processed_text.replace('{{Today}}', today_str)

    # å†œå†æ—¥æœŸ
    try:
        from zhdate import ZhDate
        # zhdate åº“ä¸æ”¯æŒ offset-aware datetimeï¼Œéœ€è¦è½¬æ¢ä¸º offset-naive
        now_naive = now.replace(tzinfo=None)
        lunar = ZhDate.from_datetime(now_naive)
        year_name = lunar.chinesestate.replace('å¹´', '')
        zodiac = lunar.chinese_era[0]  # ç”Ÿè‚–
        festival_info = f"{year_name}{zodiac}å¹´{lunar.chinesedate}"
        processed_text = processed_text.replace('{{Festival}}', festival_info)
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£… zhdateï¼Œä½¿ç”¨ç®€å•æ›¿æ¢
        processed_text = processed_text.replace('{{Festival}}', date_str)
    except Exception as e:
        logger.warning(f"å†œå†æ—¥æœŸè½¬æ¢å¤±è´¥: {e}")
        processed_text = processed_text.replace('{{Festival}}', date_str)

    # Var å¼€å¤´çš„ç¯å¢ƒå˜é‡
    for key in os.environ:
        if key.startswith('Var'):
            placeholder = f'{{{{{key}}}}}'
            value = os.getenv(key, '')
            processed_text = processed_text.replace(placeholder, value or f'æœªé…ç½®{key}')

    # EmojiPrompt
    if os.getenv('EmojiPrompt'):
        processed_text = processed_text.replace('{{EmojiPrompt}}', os.getenv('EmojiPrompt'))

    # æ’ä»¶å˜é‡
    weather_info = plugin_manager.get_placeholder_value("{{VCPWeatherInfo}}")
    processed_text = processed_text.replace('{{VCPWeatherInfo}}', weather_info)

    # MCP: {{VCPToolsAPI}} placeholder - Tools API prompt
    if '{{VCPToolsAPI}}' in processed_text:
        tools_api_prompt = await _generate_tools_api_prompt()
        processed_text = processed_text.replace('{{VCPToolsAPI}}', tools_api_prompt)

    # å•ä¸ªæ’ä»¶æè¿°
    # In MCP mode, use minimal references; otherwise use full descriptions
    individual_descriptions = plugin_manager.get_individual_plugin_descriptions()
    for placeholder_key, description in individual_descriptions.items():
        if USE_MCP_CODE_EXECUTION:
            # Extract plugin name from placeholder (format: VCPPluginName)
            plugin_name = placeholder_key[3:]  # Remove 'VCP' prefix
            mcp_reference = _get_mcp_tool_reference(plugin_name)
            processed_text = processed_text.replace(f'{{{{{placeholder_key}}}}}', mcp_reference)
        else:
            # Use full VCP description (backward compatibility)
            processed_text = processed_text.replace(f'{{{{{placeholder_key}}}}}', description)

    # Port
    if os.getenv('PORT'):
        processed_text = processed_text.replace('{{Port}}', os.getenv('PORT'))

    # Image_Key
    image_key = plugin_manager.get_resolved_plugin_config_value('ImageServer', 'Image_Key')
    if image_key:
        processed_text = processed_text.replace('{{Image_Key}}', image_key)

    # EmojiList
    if '{{EmojiList}}' in processed_text and os.getenv('EmojiList'):
        emoji_list_file = os.getenv('EmojiList')
        emoji_cache_key = emoji_list_file.replace('.txt', '').strip()
        emoji_content = cached_emoji_lists.get(emoji_cache_key)
        if emoji_content is not None:
            processed_text = processed_text.replace('{{EmojiList}}', emoji_content)
        else:
            processed_text = processed_text.replace(
                '{{EmojiList}}',
                f"[åä¸º {emoji_cache_key} çš„è¡¨æƒ…åˆ—è¡¨ä¸å¯ç”¨]"
            )

    # è¡¨æƒ…åŒ…å ä½ç¬¦ {{xxxè¡¨æƒ…åŒ…}}
    emoji_pattern = re.compile(r'\{\{(.+?è¡¨æƒ…åŒ…)\}\}')
    for match in emoji_pattern.finditer(processed_text):
        placeholder = match.group(0)
        emoji_name = match.group(1)
        emoji_list = cached_emoji_lists.get(emoji_name)
        if emoji_list:
            processed_text = processed_text.replace(placeholder, emoji_list)
        else:
            processed_text = processed_text.replace(
                placeholder,
                f'{emoji_name}åˆ—è¡¨ä¸å¯ç”¨'
            )

    # æ—¥è®°æœ¬å ä½ç¬¦ {{xxxæ—¥è®°æœ¬}}
    diary_pattern = re.compile(r'\{\{(.+?)æ—¥è®°æœ¬\}\}')
    processed_characters = set()

    for match in diary_pattern.finditer(processed_text):
        placeholder = match.group(0)
        character_name = match.group(1)

        if character_name in processed_characters:
            continue

        processed_characters.add(character_name)
        diary_dir = Path(__file__).parent / 'dailynote' / character_name
        diary_content = f"[{character_name}æ—¥è®°æœ¬å†…å®¹ä¸ºç©ºæˆ–ä¸å­˜åœ¨]"

        try:
            if diary_dir.exists():
                txt_files = sorted(diary_dir.glob('*.txt'))
                if txt_files:
                    file_contents = []
                    for txt_file in txt_files:
                        try:
                            content = txt_file.read_text(encoding='utf-8')
                            file_contents.append(content)
                        except Exception as e:
                            file_contents.append(f"[è¯»å–æ–‡ä»¶ {txt_file.name} å¤±è´¥]")
                    diary_content = '\n\n---\n\n'.join(file_contents)
        except Exception as e:
            logger.error(f"è¯»å– {character_name} æ—¥è®°ç›®å½•å‡ºé”™: {e}")
            diary_content = f"[è¯»å–{character_name}æ—¥è®°æ—¶å‡ºé”™]"

        processed_text = processed_text.replace(placeholder, diary_content)

    # ç³»ç»Ÿæç¤ºè¯è½¬æ¢è§„åˆ™
    for rule in detectors:
        detector = rule.get('detector', '')
        output = rule.get('output', '')
        if detector and output:
            processed_text = processed_text.replace(detector, output)

    # å…¨å±€ä¸Šä¸‹æ–‡è½¬æ¢è§„åˆ™
    for rule in super_detectors:
        detector = rule.get('detector', '')
        output = rule.get('output', '')
        if detector and output:
            processed_text = processed_text.replace(detector, output)

    return processed_text


async def replace_variables_in_messages(messages: List[dict]) -> List[dict]:
    """å¯¹æ¶ˆæ¯åˆ—è¡¨è¿›è¡Œå˜é‡æ›¿æ¢"""
    result = []
    for msg in messages:
        new_msg = msg.copy()

        if isinstance(new_msg.get('content'), str):
            new_msg['content'] = await replace_common_variables(msg['content'])
        elif isinstance(new_msg.get('content'), list):
            new_content = []
            for part in msg['content']:
                new_part = part.copy()
                if part.get('type') == 'text' and isinstance(part.get('text'), str):
                    new_part['text'] = await replace_common_variables(part['text'])
                new_content.append(new_part)
            new_msg['content'] = new_content

        result.append(new_msg)

    return result


# ==================== VCP åè®®è§£æ ====================

def parse_vcp_request(content: str) -> Optional[dict]:
    """
    è§£æ VCP å·¥å…·è°ƒç”¨è¯·æ±‚
    è¿”å›: {'tool_name': str, 'args': dict} æˆ– None
    """
    start_marker = "<<<[TOOL_REQUEST]>>>"
    end_marker = "<<<[END_TOOL_REQUEST]>>>"

    start_idx = content.find(start_marker)
    if start_idx == -1:
        return None

    end_idx = content.find(end_marker, start_idx)
    if end_idx == -1:
        return None

    request_block = content[start_idx + len(start_marker):end_idx].strip()

    # è§£æå‚æ•°: key:ã€Œå§‹ã€valueã€Œæœ«ã€
    param_pattern = r'([\w_]+)\s*:\s*ã€Œå§‹ã€([\s\S]*?)ã€Œæœ«ã€\s*(?:,)?'

    params = {}
    tool_name = None

    for match in re.finditer(param_pattern, request_block):
        key = match.group(1)
        value = match.group(2).strip()

        if key == 'tool_name':
            tool_name = value
        else:
            params[key] = value

    if tool_name:
        return {'tool_name': tool_name, 'args': params}

    return None


def parse_multiple_vcp_requests(content: str) -> List[dict]:
    """
    è§£æå¤šä¸ª VCP å·¥å…·è°ƒç”¨è¯·æ±‚
    è¿”å›: [{'tool_name': str, 'args': dict}, ...]
    """
    requests = []
    search_offset = 0

    while True:
        start_marker = "<<<[TOOL_REQUEST]>>>"
        end_marker = "<<<[END_TOOL_REQUEST]>>>"

        start_idx = content.find(start_marker, search_offset)
        if start_idx == -1:
            break

        end_idx = content.find(end_marker, start_idx)
        if end_idx == -1:
            break

        request_block = content[start_idx + len(start_marker):end_idx].strip()

        # è§£æå‚æ•°
        param_pattern = r'([\w_]+)\s*:\s*ã€Œå§‹ã€([\s\S]*?)ã€Œæœ«ã€\s*(?:,)?'

        params = {}
        tool_name = None

        for match in re.finditer(param_pattern, request_block):
            key = match.group(1)
            value = match.group(2).strip()

            if key == 'tool_name':
                tool_name = value
            else:
                params[key] = value

        if tool_name:
            requests.append({'tool_name': tool_name, 'args': params})

        search_offset = end_idx + len(end_marker)

    return requests


# ==================== Code Execution Detection ====================

def extract_code_blocks(content: str) -> List[str]:
    """
    Extract Python code blocks from AI response.

    Looks for:
    ```python
    code here
    ```

    Args:
        content: AI response text

    Returns:
        List of extracted code blocks
    """
    pattern = r'```python\n(.*?)```'
    return re.findall(pattern, content, re.DOTALL)


def has_code_blocks(content: str) -> bool:
    """
    Check if content contains Python code blocks.

    Args:
        content: Text to check

    Returns:
        True if Python code blocks are found
    """
    return bool(extract_code_blocks(content))


async def execute_code_blocks(content: str, timeout: float = 30.0) -> Dict[str, Any]:
    """
    Execute all Python code blocks found in content.

    Args:
        content: AI response text containing code blocks
        timeout: Maximum execution time per code block

    Returns:
        {
            'success': bool,
            'outputs': List[str],  # Output from each code block
            'errors': List[str],   # Errors from each code block
            'combined_output': str  # All outputs combined
        }
    """
    code_blocks = extract_code_blocks(content)

    if not code_blocks:
        return {
            'success': True,
            'outputs': [],
            'errors': [],
            'combined_output': ''
        }

    outputs = []
    errors = []
    all_outputs = []

    for i, code in enumerate(code_blocks):
        logger.info(f"[CodeExecution] Executing code block {i + 1}/{len(code_blocks)}")

        try:
            result = await execute_ai_code(code, timeout=timeout)

            if result['success']:
                output = result['output']
                outputs.append(output)
                all_outputs.append(output)

                if result['error']:
                    errors.append(result['error'])
                    logger.warning(f"[CodeExecution] Code block {i + 1} had stderr: {result['error']}")
            else:
                error_msg = result['error']
                errors.append(error_msg)
                logger.error(f"[CodeExecution] Code block {i + 1} failed: {error_msg}")

        except CodeExecutionError as e:
            errors.append(str(e))
            logger.error(f"[CodeExecution] Code block {i + 1} error: {e}")

    combined_output = '\n'.join(all_outputs)

    return {
        'success': len(errors) == 0,
        'outputs': outputs,
        'errors': errors,
        'combined_output': combined_output
    }


# ==================== æ—¥è®°ç³»ç»Ÿ ====================

async def handle_daily_note(note_block_content: str):
    """
    å¤„ç†æ—¥è®°å†…å®¹
    æ ¼å¼:
        Maid: xxx
        Date: xxx
        Content: xxx
    """
    lines = note_block_content.strip().split('\n')
    maid_name = None
    date_string = None
    content_lines = []
    is_content_section = False

    for line in lines:
        trimmed = line.strip()

        if trimmed.startswith('Maid:'):
            maid_name = trimmed[5:].strip()
            is_content_section = False
        elif trimmed.startswith('Date:'):
            date_string = trimmed[5:].strip()
            is_content_section = False
        elif trimmed.startswith('Content:'):
            is_content_section = True
            first_content = trimmed[8:].strip()
            if first_content:
                content_lines.append(first_content)
        elif is_content_section:
            content_lines.append(line)

    content_text = '\n'.join(content_lines).strip()

    if not all([maid_name, date_string, content_text]):
        logger.error(f"[handleDailyNote] æ— æ³•å®Œæ•´æå– Maid, Date, æˆ– Content")
        return

    # æ ¼å¼åŒ–æ—¥æœŸ
    date_part = date_string.replace('.', '.').replace('-', '.')

    now = datetime.now()
    time_string = now.strftime('%H_%M_%S')

    dir_path = Path(__file__).parent / 'dailynote' / maid_name
    filename = f"{date_part}-{time_string}.txt"
    filepath = dir_path / filename

    try:
        dir_path.mkdir(parents=True, exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"[{date_part}] - {maid_name}\n{content_text}")
        logger.info(f"[handleDailyNote] æ—¥è®°æ–‡ä»¶å†™å…¥æˆåŠŸ: {filepath}")
    except Exception as e:
        logger.error(f"[handleDailyNote] å¤„ç†æ—¥è®°æ–‡ä»¶æ—¶å‡ºé”™: {e}")


async def handle_diary_from_ai_response(response_text: str):
    """ä» AI å“åº”ä¸­æå–å’Œå¤„ç†æ—¥è®°"""
    if not response_text or not response_text.strip():
        return

    full_ai_response_text = ''

    # åˆ¤æ–­æ˜¯å¦ä¸º SSE æ ¼å¼
    lines = response_text.strip().split('\n')
    looks_like_sse = any(line.startswith('data: ') for line in lines)

    if looks_like_sse:
        # è§£æ SSE æ ¼å¼
        sse_content = ''
        for line in lines:
            if line.startswith('data: '):
                json_data = line[5:].strip()
                if json_data == '[DONE]':
                    continue
                try:
                    parsed = json.loads(json_data)
                    content_chunk = (
                        parsed.get('choices', [{}])[0].get('delta', {}).get('content') or
                        parsed.get('choices', [{}])[0].get('message', {}).get('content') or
                        ''
                    )
                    if content_chunk:
                        sse_content += content_chunk
                except json.JSONDecodeError:
                    pass
        full_ai_response_text = sse_content
    else:
        # å°è¯•è§£æä¸º JSON
        try:
            parsed = json.loads(response_text)
            full_ai_response_text = parsed.get('choices', [{}])[0].get('message', {}).get('content') or ''
        except json.JSONDecodeError:
            full_ai_response_text = response_text

    if not full_ai_response_text.strip():
        return

    # æå–æ—¥è®°å†…å®¹
    diary_pattern = re.compile(r'<<<DailyNoteStart>>>(.*?)<<<DailyNoteEnd>>>', re.DOTALL)
    match = diary_pattern.search(full_ai_response_text)

    if match:
        note_content = match.group(1).strip()
        logger.info('[DailyNote Check] æ‰¾åˆ°ç»“æ„åŒ–æ—¥è®°')
        await handle_daily_note(note_content)


# ==================== è¡¨æƒ…åŒ…ç³»ç»Ÿ ====================

async def update_and_load_emoji_list(agent_name: str, dir_path: Path, file_path: Path) -> str:
    """æ›´æ–°å¹¶åŠ è½½è¡¨æƒ…åŒ…åˆ—è¡¨"""
    print(f"å°è¯•æ›´æ–° {agent_name} è¡¨æƒ…åŒ…åˆ—è¡¨...")

    try:
        image_files = []
        if dir_path.exists():
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.JPG', '*.JPEG', '*.PNG', '*.GIF']:
                image_files.extend(dir_path.glob(ext))

        new_list = '|'.join([f.name for f in image_files])

        file_path.write_text(new_list, encoding='utf-8')
        print(f"{agent_name} è¡¨æƒ…åŒ…åˆ—è¡¨å·²æ›´æ–°å¹¶å†™å…¥ {file_path}")
        return new_list

    except Exception as e:
        error_msg = f"æ›´æ–° {agent_name} è¡¨æƒ…åŒ…åˆ—è¡¨æ—¶å‡ºé”™: {e}"
        print(error_msg)
        return error_msg


async def initialize_emoji_lists():
    """åˆå§‹åŒ–è¡¨æƒ…åŒ…åˆ—è¡¨"""
    print('å¼€å§‹åˆå§‹åŒ–è¡¨æƒ…åŒ…åˆ—è¡¨...')

    image_dir = Path(__file__).parent / 'image'

    try:
        if not image_dir.exists():
            print(f"è­¦å‘Š: image ç›®å½• {image_dir} ä¸å­˜åœ¨")
            return

        entries = [e for e in image_dir.iterdir() if e.is_dir()]
        emoji_dirs = [e for e in entries if e.name.endswith('è¡¨æƒ…åŒ…')]

        if not emoji_dirs:
            print(f"è­¦å‘Š: åœ¨ {image_dir} ç›®å½•ä¸‹æœªæ‰¾åˆ°ä»»ä½•ä»¥ 'è¡¨æƒ…åŒ…' ç»“å°¾çš„æ–‡ä»¶å¤¹")
            return

        print(f"æ‰¾åˆ° {len(emoji_dirs)} ä¸ªè¡¨æƒ…åŒ…ç›®å½•ï¼Œå¼€å§‹åŠ è½½...")

        for emoji_dir in emoji_dirs:
            emoji_name = emoji_dir.name
            txt_file = Path(__file__).parent / f'{emoji_name}.txt'

            try:
                content = await update_and_load_emoji_list(emoji_name, emoji_dir, txt_file)
                cached_emoji_lists[emoji_name] = content
            except Exception as e:
                print(f"åŠ è½½ {emoji_name} åˆ—è¡¨æ—¶å‡ºé”™: {e}")
                cached_emoji_lists[emoji_name] = f'{emoji_name}åˆ—è¡¨åŠ è½½å¤±è´¥'

        print('æ‰€æœ‰è¡¨æƒ…åŒ…åˆ—è¡¨åŠ è½½å®Œæˆã€‚')

    except Exception as e:
        print(f"è¯»å– image ç›®å½• {image_dir} æ—¶å‡ºé”™: {e}")

    print('è¡¨æƒ…åŒ…åˆ—è¡¨åˆå§‹åŒ–ç»“æŸã€‚')


# ==================== FastAPI åº”ç”¨ ====================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶
    logger.info('å¼€å§‹åŠ è½½æ’ä»¶...')
    await plugin_manager.load_plugins()
    logger.info('æ’ä»¶åŠ è½½å®Œæˆã€‚')

    plugin_manager.set_project_base_path(str(Path(__file__).parent))

    logger.info('å¼€å§‹åˆå§‹åŒ–æœåŠ¡ç±»æ’ä»¶...')
    # æ³¨æ„: initialize_services éœ€è¦ app å®ä¾‹ï¼Œåœ¨è·¯ç”±è®¾ç½®åå†è°ƒç”¨
    logger.info('æœåŠ¡ç±»æ’ä»¶åˆå§‹åŒ–å®Œæˆã€‚')

    logger.info('å¼€å§‹åˆå§‹åŒ–é™æ€æ’ä»¶...')
    await plugin_manager.initialize_static_plugins()
    logger.info('é™æ€æ’ä»¶åˆå§‹åŒ–å®Œæˆã€‚')

    await initialize_emoji_lists()

    yield

    # å…³é—­æ—¶
    logger.info('Initiating graceful shutdown...')
    await plugin_manager.shutdown_all_plugins()
    logger.info('Graceful shutdown complete.')


app = FastAPI(lifespan=lifespan)

# CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Import routes after app is created to register them
import routes.setting
import routes.agent
routes.setting.register_routes(app)
routes.agent.register_routes(app)

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
agent_dir = Path(__file__).parent / 'Agent'
if agent_dir.exists():
    app.mount("/Agent", StaticFiles(directory=str(agent_dir)), name="agent_files")
    logger.info(f"å·²æŒ‚è½½ Agent é™æ€æ–‡ä»¶ç›®å½•: {agent_dir}")
else:
    logger.warning(f"Agent ç›®å½•ä¸å­˜åœ¨: {agent_dir}")

@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    """è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶"""
    logger.info(f"Received {request.method} request for {request.url.path} from {request.client.host}")
    return await call_next(request)


# ==================== è·¯ç”± ====================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {"message": "VCPToolBox Server (Python)"}


@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    """
    å¤„ç†èŠå¤©å®Œæˆè¯·æ±‚
    è¿™æ˜¯æ ¸å¿ƒåŠŸèƒ½ï¼Œå¤„ç†å›¾ç‰‡é¢„å¤„ç†ã€å˜é‡æ›¿æ¢ã€å·¥å…·è°ƒç”¨ç­‰
    """
    try:
        original_body = await request.json()
        await write_debug_log('LogInput', original_body)

        # ==================== 1. å›¾ç‰‡é¢„å¤„ç† ====================
        should_process_images = True

        if 'messages' in original_body:
            for msg in original_body['messages']:
                content = msg.get('content', '')
                found_placeholder = False

                if isinstance(content, str) and '{{ShowBase64}}' in content:
                    found_placeholder = True
                    msg['content'] = content.replace('{{ShowBase64}}', '')
                elif isinstance(content, list):
                    for part in content:
                        if part.get('type') == 'text' and '{{ShowBase64}}' in part.get('text', ''):
                            found_placeholder = True
                            part['text'] = part['text'].replace('{{ShowBase64}}', '')

                if found_placeholder:
                    should_process_images = False
                    logger.info('[Server] Image processing disabled by {{ShowBase64}} placeholder')
                    break

        if should_process_images:
            logger.info('[Server] Image processing enabled, calling ImageProcessor plugin...')
            try:
                original_body['messages'] = await plugin_manager.execute_message_preprocessor(
                    "ImageProcessor", original_body['messages']
                )
                logger.info('[Server] ImageProcessor plugin finished.')
            except Exception as e:
                logger.error(f'[Server] Error executing ImageProcessor plugin: {e}')

        # ==================== 2. å˜é‡æ›¿æ¢ ====================
        if 'messages' in original_body:
            original_body['messages'] = await replace_variables_in_messages(original_body['messages'])

        await write_debug_log('LogOutputAfterProcessing', original_body)

        # ==================== 3. è°ƒç”¨ AI API ====================
        is_streaming = original_body.get('stream', False)

        async with httpx.AsyncClient(timeout=300.0) as client:
            ai_response = await client.post(
                f"{API_URL}/v1/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {API_KEY}",
                    "User-Agent": request.headers.get("user-agent", "VCPToolBox/1.0"),
                    "Accept": "text/event-stream" if is_streaming else "application/json",
                },
                json=original_body
            )

        # ==================== 4. å¤„ç†å“åº” ====================
        if is_streaming:
            # æµå¼å“åº”å¤„ç†
            return await handle_streaming_response(ai_response, original_body, request)
        else:
            # éæµå¼å“åº”å¤„ç†
            return await handle_non_streaming_response(ai_response, original_body, request)

    except Exception as e:
        logger.error(f'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}')
        import traceback
        traceback.print_exc()
        return JSONResponse(
            status_code=500,
            content={"error": "Internal Server Error", "details": str(e)}
        )


async def handle_streaming_response(ai_response: httpx.Response, original_body: dict, request: Request):
    """
    å¤„ç†æµå¼ AI å“åº”
    æ”¯æŒ: æ£€æµ‹å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œæ’ä»¶ï¼Œè¿›è¡Œç¬¬äºŒæ¬¡ AI è°ƒç”¨
    """
    async def generate_stream():
        """å†…éƒ¨ç”Ÿæˆå™¨å‡½æ•°ï¼Œäº§ç”Ÿæµå¼å“åº”"""
        # æ”¶é›†å®Œæ•´çš„æµå¼å“åº”å†…å®¹
        full_content = ''
        line_buffer = ''

        # ç¬¬ä¸€é˜¶æ®µ: è½¬å‘åŸå§‹æµå¼å“åº”
        async for chunk in ai_response.aiter_bytes():
            chunk_str = chunk.decode('utf-8', errors='ignore')
            full_content += chunk_str
            line_buffer += chunk_str

            # æŒ‰è¡Œåˆ†å‰²å¤„ç†
            lines = line_buffer.split('\n')
            line_buffer = lines.pop()  # ä¿ç•™æœ€åä¸€è¡Œï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰

            # è½¬å‘å®Œæ•´çš„è¡Œ
            for line in lines:
                if line.strip() and line.strip() != 'data: [DONE]':
                    yield f'{line}\n'
                elif line.strip() == '':
                    yield '\n'

        # å¤„ç†å‰©ä½™çš„ buffer
        if line_buffer.strip() and line_buffer.strip() != 'data: [DONE]':
            yield f'{line_buffer}\n'

        # ä» SSE æ•°æ®ä¸­æå–å®é™…å†…å®¹
        sse_content = ''
        for line in full_content.split('\n'):
            if line.startswith('data: '):
                json_data = line[5:].strip()
                if json_data == '[DONE]':
                    continue
                try:
                    parsed = json.loads(json_data)
                    content_chunk = parsed.get('choices', [{}])[0].get('delta', {}).get('content') or ''
                    if content_chunk:
                        sse_content += content_chunk
                except json.JSONDecodeError:
                    pass

        logger.info(f'[PluginCall] AI First Full Response Text: {sse_content[:200]}...')

        # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ä»£ç å—ï¼ˆæ–°çš„MCPæ–¹å¼ï¼‰
        has_code = has_code_blocks(sse_content)

        if has_code:
            # æ‰§è¡Œä»£ç å—
            yield 'data: [CODE_EXECUTION]\n\n'
            logger.info('[CodeExecution] Found Python code blocks, executing...')

            try:
                code_result = await execute_code_blocks(sse_content, timeout=30.0)

                if code_result['success']:
                    code_output = code_result['combined_output']
                    logger.info(f'[CodeExecution] Execution successful, output: {code_output[:200]}...')

                    # å‡†å¤‡ç¬¬äºŒæ¬¡è°ƒç”¨çš„æ¶ˆæ¯
                    messages_for_next_call = original_body.get('messages', []).copy()
                    messages_for_next_call.append({'role': 'assistant', 'content': sse_content})

                    # æ·»åŠ ä»£ç æ‰§è¡Œç»“æœ
                    if code_output:
                        result_message = f"ä»£ç æ‰§è¡Œç»“æœ:\n{code_output}"
                    else:
                        result_message = "ä»£ç æ‰§è¡Œå®Œæˆï¼Œä½†æ²¡æœ‰è¾“å‡ºã€‚"

                    messages_for_next_call.append({'role': 'user', 'content': result_message})

                    # ç¬¬äºŒæ¬¡ AI è°ƒç”¨
                    logger.info('[CodeExecution] Proceeding with second AI call after code execution')
                    await write_debug_log('LogOutputWithCodeExecution_BeforeSecondCall', {
                        'messages': messages_for_next_call,
                        'originalRequestBody': original_body
                    })

                    async with httpx.AsyncClient(timeout=300.0) as client:
                        second_response = await client.post(
                            f"{API_URL}/v1/chat/completions",
                            headers={
                                "Content-Type": "application/json",
                                "Authorization": f"Bearer {API_KEY}",
                                "User-Agent": request.headers.get("user-agent", "VCPToolBox/1.0"),
                                "Accept": "text/event-stream",
                            },
                            json={**original_body, 'messages': messages_for_next_call}
                        )

                    # æµå¼è½¬å‘ç¬¬äºŒæ¬¡ AI å“åº”
                    second_full_text = ''
                    async for chunk in second_response.aiter_bytes():
                        chunk_str = chunk.decode('utf-8', errors='ignore')
                        second_full_text += chunk_str
                        yield chunk_str

                    yield 'data: [DONE]\n\n'

                    # å¤„ç†æ—¥è®°
                    await handle_diary_from_ai_response(second_full_text)

                else:
                    # ä»£ç æ‰§è¡Œå¤±è´¥
                    error_msg = code_result['errors'][0] if code_result['errors'] else "Unknown error"
                    logger.error(f'[CodeExecution] Execution failed: {error_msg}')

                    yield f"data: {{'error': 'Code execution failed: {error_msg}'}}\n\n"
                    yield 'data: [DONE]\n\n'
                    await handle_diary_from_ai_response(full_content)

            except Exception as e:
                logger.error(f'[CodeExecution] Error during code execution: {e}')
                import traceback
                traceback.print_exc()
                yield f"data: {{'error': '{str(e)}'}}\n\n"
                yield 'data: [DONE]\n\n'
                await handle_diary_from_ai_response(full_content)

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆVCPæ–¹å¼ï¼Œå‘åå…¼å®¹ï¼‰
        vcp_request = parse_vcp_request(sse_content)
        needs_second_ai_call = vcp_request is not None

        if needs_second_ai_call:
            # æœ‰å·¥å…·è°ƒç”¨ï¼Œéœ€è¦æ‰§è¡Œå¹¶è¿”å›ç¬¬äºŒæ¬¡ AI è°ƒç”¨
            yield 'data: [TOOL_CALL_DETECTED]\n\n'

            # å‡†å¤‡ç¬¬äºŒæ¬¡è°ƒç”¨çš„æ¶ˆæ¯
            messages_for_next_call = original_body.get('messages', []).copy()
            messages_for_next_call.append({'role': 'assistant', 'content': sse_content})

            tool_name = vcp_request['tool_name']
            tool_args = vcp_request['args']

            try:
                logger.info(f"[PluginCall] Executing tool: {tool_name} with args: {tool_args}")
                plugin_result = await plugin_manager.process_tool_call(tool_name, tool_args)

                if plugin_result is not None:
                    message_content = f"æ¥è‡ªå·¥å…· \"{tool_name}\" çš„ç»“æœ:\n{json.dumps(plugin_result, ensure_ascii=False, indent=2)}"
                else:
                    message_content = f"æ¥è‡ªå·¥å…· \"{tool_name}\" çš„ç»“æœ:\næ’ä»¶ {tool_name} æ‰§è¡Œå®Œæ¯•ï¼Œä½†æ²¡æœ‰è¿”å›æ˜ç¡®å†…å®¹ã€‚"

                messages_for_next_call.append({'role': 'user', 'content': message_content})

                # ç¬¬äºŒæ¬¡ AI è°ƒç”¨
                logger.info('[PluginCall] Proceeding with second AI call with tool results')
                await write_debug_log('LogOutputWithPluginCall_BeforeSecondCall', {
                    'messages': messages_for_next_call,
                    'originalRequestBody': original_body
                })

                async with httpx.AsyncClient(timeout=300.0) as client:
                    second_response = await client.post(
                        f"{API_URL}/v1/chat/completions",
                        headers={
                            "Content-Type": "application/json",
                            "Authorization": f"Bearer {API_KEY}",
                            "User-Agent": request.headers.get("user-agent", "VCPToolBox/1.0"),
                            "Accept": "text/event-stream",
                        },
                        json={**original_body, 'messages': messages_for_next_call}
                    )

                # æµå¼è½¬å‘ç¬¬äºŒæ¬¡ AI å“åº”
                second_full_text = ''
                async for chunk in second_response.aiter_bytes():
                    chunk_str = chunk.decode('utf-8', errors='ignore')
                    second_full_text += chunk_str
                    yield chunk_str

                yield 'data: [DONE]\n\n'

                # å¤„ç†æ—¥è®°
                await handle_diary_from_ai_response(second_full_text)

            except Exception as e:
                logger.error(f'[PluginCall] Error during tool execution or second AI call: {e}')
                import traceback
                traceback.print_exc()
                yield f"data: {{'error': '{str(e)}'}}\n\n"
                yield 'data: [DONE]\n\n'
                await handle_diary_from_ai_response(full_content)
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸæµ
            yield 'data: [DONE]\n\n'
            # å¤„ç†æ—¥è®°
            await handle_diary_from_ai_response(full_content)

    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        }
    )


async def handle_non_streaming_response(
    ai_response: httpx.Response,
    original_body: dict,
    request: Request
):
    """å¤„ç†éæµå¼ AI å“åº”ï¼ˆæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨ï¼‰"""
    response_text = ai_response.content.decode('utf-8')
    await write_debug_log('LogFirstAIResponse', response_text)

    try:
        response_json = json.loads(response_text)
        full_content_from_ai = response_json.get('choices', [{}])[0].get('message', {}).get('content', '')
    except json.JSONDecodeError:
        full_content_from_ai = response_text

    # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ä»£ç å—ï¼ˆæ–°çš„MCPæ–¹å¼ï¼‰
    if has_code_blocks(full_content_from_ai):
        logger.info('[CodeExecution] Found Python code blocks in non-streaming response')
        code_result = await execute_code_blocks(full_content_from_ai, timeout=30.0)

        if code_result['success']:
            code_output = code_result['combined_output']
            logger.info(f'[CodeExecution] Execution successful')

            # æ„å»ºåŒ…å«ä»£ç æ‰§è¡Œç»“æœçš„å“åº”
            try:
                response_json = json.loads(response_text)
                # æ›´æ–°å“åº”å†…å®¹ï¼Œæ·»åŠ ä»£ç æ‰§è¡Œç»“æœ
                response_json['choices'][0]['message']['content'] = (
                    full_content_from_ai + "\n\nä»£ç æ‰§è¡Œç»“æœ:\n" + code_output
                )
                response_json['choices'][0]['finish_reason'] = 'stop'

                await handle_diary_from_ai_response(json.dumps(response_json))
                return JSONResponse(content=response_json)

            except json.JSONDecodeError:
                # å¦‚æœæ— æ³•è§£æä¸ºJSONï¼Œè¿”å›åŸå§‹æ–‡æœ¬
                new_response_text = response_text + "\n\nä»£ç æ‰§è¡Œç»“æœ:\n" + code_output
                await handle_diary_from_ai_response(new_response_text)
                return Response(content=new_response_text, media_type="text/plain")
        else:
            # ä»£ç æ‰§è¡Œå¤±è´¥
            error_msg = code_result['errors'][0] if code_result['errors'] else "Unknown error"
            logger.error(f'[CodeExecution] Execution failed: {error_msg}')

            try:
                response_json = json.loads(response_text)
                response_json['choices'][0]['message']['content'] = (
                    full_content_from_ai + f"\n\nä»£ç æ‰§è¡Œå¤±è´¥: {error_msg}"
                )
                return JSONResponse(content=response_json)
            except json.JSONDecodeError:
                return Response(
                    content=response_text + f"\n\nä»£ç æ‰§è¡Œå¤±è´¥: {error_msg}",
                    media_type="text/plain"
                )

    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆVCPæ–¹å¼ï¼Œå‘åå…¼å®¹ï¼‰
    vcp_requests = parse_multiple_vcp_requests(full_content_from_ai)

    if not vcp_requests:
        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›
        await handle_diary_from_ai_response(response_text)
        return Response(content=ai_response.content, media_type="application/json")

    # å¤„ç†å¤šè½®å·¥å…·è°ƒç”¨
    max_recursion = 5
    conversation_history = []
    current_ai_content = full_content_from_ai
    current_messages = original_body.get('messages', []).copy()

    for recursion_depth in range(max_recursion):
        # æ·»åŠ  AI å“åº”åˆ°å†å²
        conversation_history.append({'type': 'ai', 'content': current_ai_content})

        # æ£€æŸ¥å½“å‰ AI å“åº”ä¸­çš„å·¥å…·è°ƒç”¨
        vcp_requests = parse_multiple_vcp_requests(current_ai_content)

        if not vcp_requests:
            # æ²¡æœ‰æ›´å¤šå·¥å…·è°ƒç”¨ï¼Œé€€å‡ºå¾ªç¯
            break

        # æ·»åŠ  AI å“åº”åˆ°æ¶ˆæ¯å†å²
        current_messages.append({'role': 'assistant', 'content': current_ai_content})

        # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        tool_results = []
        for tool_request in vcp_requests:
            tool_name = tool_request['tool_name']
            tool_args = tool_request['args']

            try:
                logger.info(f"[Multi-Tool] Executing tool: {tool_name} with args: {tool_args}")
                plugin_result = await plugin_manager.process_tool_call(tool_name, tool_args)

                if SHOW_VCP_OUTPUT:
                    conversation_history.append({
                        'type': 'vcp',
                        'content': f"å·¥å…· {tool_name} è°ƒç”¨ç»“æœ:\n{plugin_result}"
                    })

                tool_results.append(f"æ¥è‡ªå·¥å…· \"{tool_name}\" çš„ç»“æœ:\n{plugin_result}")

            except Exception as e:
                logger.error(f"[Multi-Tool] Error executing plugin {tool_name}: {e}")
                error_msg = f"æ‰§è¡Œæ’ä»¶ {tool_name} æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
                if SHOW_VCP_OUTPUT:
                    conversation_history.append({'type': 'vcp', 'content': error_msg})
                tool_results.append(error_msg)

        # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
        combined_results = "\n\n---\n\n".join(tool_results)
        current_messages.append({'role': 'user', 'content': combined_results})

        # è°ƒç”¨ä¸‹ä¸€è½® AI
        logger.info("[Multi-Tool] Fetching next AI response after processing tools")

        async with httpx.AsyncClient(timeout=300.0) as client:
            next_response = await client.post(
                f"{API_URL}/v1/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {API_KEY}",
                },
                json={**original_body, 'messages': current_messages, 'stream': False}
            )

        next_response_text = next_response.content.decode('utf-8')

        try:
            next_response_json = json.loads(next_response_text)
            current_ai_content = next_response_json.get('choices', [{}])[0].get('message', {}).get('content', '')
        except json.JSONDecodeError:
            current_ai_content = next_response_text

    # æ„å»ºæœ€ç»ˆå“åº”
    final_content = ''
    for item in conversation_history:
        if item['type'] == 'ai':
            final_content += item['content']
        elif item['type'] == 'vcp' and SHOW_VCP_OUTPUT:
            final_content += f"\n<<<[VCP_RESULT]>>>\n{item['content']}\n<<<[END_VCP_RESULT]>>>\n"

    # æ·»åŠ æœ€åçš„ AI å“åº”
    final_content += current_ai_content

    # æ„å»ºå“åº” JSON
    try:
        final_json = json.loads(response_text)
        if not final_json.get('choices'):
            final_json['choices'] = [{}]
        final_json['choices'][0]['message']['content'] = final_content
        final_json['choices'][0]['finish_reason'] = 'stop'
    except json.JSONDecodeError:
        final_json = {
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": final_content
                },
                "finish_reason": "stop"
            }]
        }

    await handle_diary_from_ai_response(response_text)

    return JSONResponse(content=final_json)


# ==================== å¯åŠ¨æœåŠ¡å™¨ ====================

if __name__ == "__main__":
    import uvicorn

    # åœ¨å¯åŠ¨ååˆå§‹åŒ–æœåŠ¡æ’ä»¶
    @app.on_event("startup")
    async def startup_event():
        """å¯åŠ¨äº‹ä»¶"""
        await ensure_debug_log_dir()

        # åˆå§‹åŒ–æœåŠ¡æ’ä»¶ï¼ˆéœ€è¦åœ¨ app åˆ›å»ºåè°ƒç”¨ï¼‰
        plugin_manager.initialize_services(app, str(Path(__file__).parent))

    logger.info(f"ä¸­é—´å±‚æœåŠ¡å™¨æ­£åœ¨ç›‘å¬ç«¯å£ {PORT}")
    logger.info(f"API æœåŠ¡å™¨åœ°å€: {API_URL}")

    uvicorn.run(app, host="0.0.0.0", port=PORT, log_level="info")
