[
  {
    "speaker": "主持人",
    "dialogue": "今天我们聊一聊携程金融的缓存架构演进。听说你们从零开始搭建了一套统一缓存服务，叫 utag？能先简单介绍一下背景吗？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "当然可以。随着业务增长，我们金融系统形成了多层架构——业务层、平台层、基础服务层。像用户信息、产品信息这些基础数据，被大量上层服务高频调用。直接查 DB 压力太大，响应也慢，所以我们构建了 utag 这个统一缓存服务，目标是实现‘全量、准实时、永久有效’的缓存能力。"
  },
  {
    "speaker": "主持人",
    "dialogue": "听起来很理想！但引入缓存就绕不开一致性问题。你们提到 utag 是‘最终一致性’的，那在数据准确性上是怎么保障的？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "这是个关键点。我们设计了三大触发源：binlog 变更、业务 MQ，还有定时扫表任务。它们互为备份，确保不会漏掉任何一次 DB 更新。一旦触发，我们会查询最新 DB 数据，发一条统一的缓存更新 MQ，由多地机房的 utag 实例消费并更新本地 Redis。"
  },
  {
    "speaker": "主持人",
    "dialogue": "多个触发源会不会导致同一条数据被并发更新？比如 binlog 和 MQ 同时触发，缓存反而写错了？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "问得好！确实存在这种风险。所以我们做了两层控制：第一，用 Redis 分布式锁把‘查老缓存→比对→更新’这三步串行化；第二，比对新老数据的 updateTime。只有新数据的 updateTime 更大，才允许覆盖缓存。"
  },
  {
    "speaker": "主持人",
    "dialogue": "但如果同一秒内更新了两次呢？比如 value 先变 1 再变 2，updateTime 都是同一秒，怎么保证最终是 2？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "这时候我们有个巧妙的设计：如果发现新老数据 updateTime 相同但值不同，就认为可能存在乱序，于是发一条延迟 1 秒的 MQ 消息。等这一秒过去后，再重新查 DB，确保拿到的是最终值。这样即使先写了 1，后续也会被 2 覆盖回来。"
  },
  {
    "speaker": "主持人",
    "dialogue": "明白了！那除了单条数据准确，utag 还要缓存全量数据。怎么保证完整性？万一某个触发源挂了，会不会丢数据？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "所以我们不把鸡蛋放一个篮子里。三种触发源同时工作，互相兜底。此外，每周还有一次全表扫描任务做兜底同步，再加上独立的数据校验任务，定期比对 Redis 和 DB 的差异并自动补偿。这样即使某条链路故障，整体数据完整性依然有保障。"
  },
  {
    "speaker": "主持人",
    "dialogue": "最后一个问题：utag 是跨机房部署的，怎么保证高可用？比如 A 机房 Redis 挂了，B 机能顶上吗？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "可以的。我们 AB 两地都部署了 utag 和 Redis，通过公司级 MQ（QMQ + Kafka 双通道）同步更新。业务调用优先走本地机房，如果本地 Redis 异常，可以通过配置快速降级到调用异地接口。我们还用 Dubbo 的 RpcContext 透传标识，防止降级时循环调用。"
  },
  {
    "speaker": "主持人",
    "dialogue": "今天我们聊到携程金融在强一致性缓存场景下的实践，特别是在贷前服务中。我听说你们对数据一致性要求非常高，能先简单说说为什么不能用最终一致性的方案吗？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "确实，在贷前服务里，比如用户刚开通某个信贷产品，系统马上就要基于最新状态做决策。如果缓存里还是老数据，哪怕只错几毫秒，都可能导致风控判断错误或者用户体验问题。所以必须保证缓存和DB在关键操作上严格一致。"
  },
  {
    "speaker": "主持人",
    "dialogue": "明白了。那你们采用的是‘先更新DB，再删除缓存’的模式，但这种模式其实存在并发风险，对吧？具体有哪些典型问题？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "主要有两类。第一种是：DB刚更新完、还没删缓存的时候，另一个请求正好命中了缓存，就返回了旧数据。第二种更隐蔽——当缓存失效时，查询会去加载新数据，但如果这个加载过程发生在DB更新之后、缓存删除之前，它可能把旧的DB值又写回缓存，造成脏数据。"
  },
  {
    "speaker": "主持人",
    "dialogue": "听起来挺棘手的。那你们怎么解决这些问题的？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "核心思路就是加锁。我们在两个关键路径上都加了Redis分布式锁：一个是‘更新DB + 删除缓存’这个写流程，另一个是‘查DB + 写缓存’这个读流程。只要锁key相同，就能串行化操作，避免并发冲突。"
  },
  {
    "speaker": "主持人",
    "dialogue": "那这个锁的粒度怎么定？是在事务开始前加，还是提交后再加？我听说这会影响性能和一致性之间的平衡。"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "没错。我们默认是在事务开始前就加锁，覆盖整个DB更新和缓存删除过程。这样一致性最强。但万一Redis临时抖动导致加锁失败，我们会自动降级到‘事务提交后再加锁删缓存’。虽然极端情况下可能短暂不一致，但概率极低，而且主业务不受影响。"
  },
  {
    "speaker": "主持人",
    "dialogue": "说到故障，如果删缓存失败了怎么办？比如网络中断，DB改了但缓存没删掉，岂不是长期不一致？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "这是个好问题。我们借鉴了事务消息的思想，建了一张本地表叫 cache_key_queue。每次DB更新时，会把要删的缓存key和业务操作放在同一个事务里写入这张表。删缓存成功后，才删掉这条记录。如果删失败了，后台定时任务会不断重试，直到清理干净。这样即使Redis宕机几小时，恢复后也能自动修复一致性。"
  },
  {
    "speaker": "主持人",
    "dialogue": "这个设计很巧妙！既保证了可靠性，又没引入外部依赖。最后问一句，这套方案上线后效果如何？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "效果很明显。数据库QPS下降了80%，缓存命中率高达92%。虽然加锁理论上会增加延迟，但因为命中率高，整体接口平均响应时间反而降低了10%左右。最关键的是，两年多来没出现过因缓存导致的数据不一致事故。"
  },
  {
    "speaker": "主持人",
    "dialogue": "今天我们聊到了携程金融在缓存设计上的两种典型方案。最后这个段落特别提到了高可用保障和熔断恢复机制，嘉宾你能具体说说，当 Redis 缓存服务突然不可用了，系统是怎么应对的吗？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "当然可以。我们的基本原则是：缓存只是辅助手段，不能强依赖。所以一旦 Redis 出问题，主业务必须还能跑。我们采用的是单机级别的熔断机制——不是集群统一熔断，而是每台应用服务器自己判断。比如在10秒内 Redis 操作异常超过50次，就自动开启熔断，跳过所有缓存操作，直接读写 DB。这样能避免因为重试锁或缓存调用拖慢主流程。"
  },
  {
    "speaker": "主持人",
    "dialogue": "明白了，那 Redis 恢复之后呢？是不是直接就能重新开始用缓存了？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "没那么简单！恢复是分阶段的。首先，系统会探测 Redis 是否真的可用，比如连续成功执行几次 set 操作。确认可用后，先恢复‘写’操作——也就是更新 DB 后能正常删缓存。但这时候还不能恢复‘读’，因为 Redis 不可用期间 DB 可能已经变了，而缓存里还是老数据。所以我们有个补偿队列叫 cache_key_queue，专门记录那些该删但没删成的 key。只有等这个队列清空了，才安全地恢复读缓存。"
  },
  {
    "speaker": "主持人",
    "dialogue": "这个设计很细致啊！那如果缓存彻底丢了，比如机房故障导致 Redis 数据全没了，怎么办？"
  },
  {
    "speaker": "嘉宾",
    "dialogue": "这种情况我们有兜底方案：全量快速重建。通过并行调度任务，在30分钟内把整个 DB 表的数据重新刷进 Redis。不过这需要人工判断后手动触发，毕竟代价不小。其实这也体现了我们两套方案的核心差异：最终一致性场景下，缓存是‘优先读’的，靠补偿保证最终正确；而强一致性场景，比如贷前服务，宁可多查 DB，也绝不容忍脏数据。选哪种，完全取决于业务对一致性的容忍度。"
  }
]